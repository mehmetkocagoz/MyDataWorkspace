{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape=b</th>\n",
       "      <th>cap-shape=c</th>\n",
       "      <th>cap-shape=f</th>\n",
       "      <th>cap-shape=k</th>\n",
       "      <th>cap-shape=s</th>\n",
       "      <th>cap-shape=x</th>\n",
       "      <th>cap-surface=f</th>\n",
       "      <th>cap-surface=g</th>\n",
       "      <th>cap-surface=s</th>\n",
       "      <th>cap-surface=y</th>\n",
       "      <th>...</th>\n",
       "      <th>population=v</th>\n",
       "      <th>population=y</th>\n",
       "      <th>habitat=d</th>\n",
       "      <th>habitat=g</th>\n",
       "      <th>habitat=l</th>\n",
       "      <th>habitat=m</th>\n",
       "      <th>habitat=p</th>\n",
       "      <th>habitat=u</th>\n",
       "      <th>habitat=w</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows Ã— 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cap-shape=b cap-shape=c cap-shape=f cap-shape=k cap-shape=s cap-shape=x  \\\n",
       "0              F           F           F           F           F           T   \n",
       "1              F           F           F           F           F           T   \n",
       "2              T           F           F           F           F           F   \n",
       "3              F           F           F           F           F           T   \n",
       "4              F           F           F           F           F           T   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "8119           F           F           F           T           F           F   \n",
       "8120           F           F           F           F           F           T   \n",
       "8121           F           F           T           F           F           F   \n",
       "8122           F           F           F           T           F           F   \n",
       "8123           F           F           F           F           F           T   \n",
       "\n",
       "     cap-surface=f cap-surface=g cap-surface=s cap-surface=y  ...  \\\n",
       "0                F             F             T             F  ...   \n",
       "1                F             F             T             F  ...   \n",
       "2                F             F             T             F  ...   \n",
       "3                F             F             F             T  ...   \n",
       "4                F             F             T             F  ...   \n",
       "...            ...           ...           ...           ...  ...   \n",
       "8119             F             F             T             F  ...   \n",
       "8120             F             F             T             F  ...   \n",
       "8121             F             F             T             F  ...   \n",
       "8122             F             F             F             T  ...   \n",
       "8123             F             F             T             F  ...   \n",
       "\n",
       "     population=v population=y habitat=d habitat=g habitat=l habitat=m  \\\n",
       "0               F            F         F         F         F         F   \n",
       "1               F            F         F         T         F         F   \n",
       "2               F            F         F         F         F         T   \n",
       "3               F            F         F         F         F         F   \n",
       "4               F            F         F         T         F         F   \n",
       "...           ...          ...       ...       ...       ...       ...   \n",
       "8119            F            F         F         F         T         F   \n",
       "8120            T            F         F         F         T         F   \n",
       "8121            F            F         F         F         T         F   \n",
       "8122            T            F         F         F         T         F   \n",
       "8123            F            F         F         F         T         F   \n",
       "\n",
       "     habitat=p habitat=u habitat=w class  \n",
       "0            F         T         F     B  \n",
       "1            F         F         F     A  \n",
       "2            F         F         F     A  \n",
       "3            F         T         F     B  \n",
       "4            F         F         F     A  \n",
       "...        ...       ...       ...   ...  \n",
       "8119         F         F         F     A  \n",
       "8120         F         F         F     A  \n",
       "8121         F         F         F     A  \n",
       "8122         F         F         F     B  \n",
       "8123         F         F         F     A  \n",
       "\n",
       "[8124 rows x 113 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('dataset/data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn naive_bayes does not support categorical values in X \n",
    "## Therefore, I'll use label_encoder which transform T to 1 and F to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = data.drop(columns=['class'])\n",
    "y = data['class']\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object' and len(X[column].unique()) == 2:\n",
    "        X[column] = label_encoder.fit_transform(X[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Naive Bayes algorithm for binary classification. Use stratified 10-folds cross-validation to measure the performance of the algorithm.\n",
    "## 10-folds means in each iteration of cross-validation, the model is trained on 9*(dataset_size/10) samples and rest will be using on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To measure performance metrics I will store TP, TN, FP, FN in each stratified k-fold iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Averages:\n",
      "Accuracy:  0.9438706911699659\n",
      "TPrate (Recall):  0.9457895952969642\n",
      "TNrate:  0.9457895952969642\n",
      "Precision:  0.947778909104917\n",
      "F-Score:  0.9438461751393117\n",
      "\n",
      "\n",
      "Micro Averages:\n",
      "Accuracy:  0.9438706911699659\n",
      "Tprate (Recall):  0.9438706911699659\n",
      "Tnrate:  0.9438706911699659\n",
      "Precision:  0.9438706911699659\n",
      "F-Score:  0.9438706911699659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "\n",
    "# use n_splits = 10 for 10-folds\n",
    "# Initialize stratified 10-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Parameters for calculating macro-average metrics\n",
    "tn_A, fp_A, fn_A, tp_A = 0,0,0,0\n",
    "tn_B, fp_B, fn_B, tp_B = 0,0,0,0\n",
    "\n",
    "\n",
    "# Initialize variables for accumulating macro-average metrics for class A\n",
    "total_fold_accuracy_macro_A = 0\n",
    "total_fold_precision_macro_A = 0\n",
    "total_fold_recall_macro_A = 0\n",
    "total_fold_tn_rate_macro_A = 0\n",
    "total_fold_f1_macro_A = 0\n",
    "\n",
    "# Initialize variables for accumulating macro-average metrics for class B\n",
    "total_fold_accuracy_macro_B = 0\n",
    "total_fold_precision_macro_B = 0\n",
    "total_fold_recall_macro_B = 0\n",
    "total_fold_tn_rate_macro_B = 0\n",
    "total_fold_f1_macro_B = 0\n",
    "\n",
    "# Parameters for calculating micro-average metrics\n",
    "\n",
    "total_fold_accuracy_micro = 0\n",
    "total_fold_precision_micro = 0\n",
    "total_fold_recall_micro = 0\n",
    "total_fold_tn_rate_micro = 0 \n",
    "total_fold_f1_micro = 0\n",
    "\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train Naive Bayes classifier\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    # tn means the model predicted the negative and the actual label was also negative\n",
    "    # fp means the model predicted the positive and the actual label was negative\n",
    "    # fn means the model predicted the negative and the actual label was positive\n",
    "    # tn means the model predicted the negative and the actual label was also negative\n",
    "\n",
    "    # our negative class is B\n",
    "    # our positive class is A\n",
    "    tn_A = sum((y_pred == 'B')&(y_test == 'B'))\n",
    "    fp_A = sum((y_pred == 'A')&(y_test == 'B'))\n",
    "    fn_A = sum((y_pred == 'B')&(y_test == 'A'))\n",
    "    tp_A = sum((y_pred == 'A')&(y_test == 'A'))\n",
    "    \n",
    "    # our negative class is A\n",
    "    # our positive class is B\n",
    "    tn_B = sum((y_pred == 'A')&(y_test == 'A'))\n",
    "    fp_B = sum((y_pred == 'B')&(y_test == 'A'))\n",
    "    fn_B = sum((y_pred == 'A')&(y_test == 'B'))\n",
    "    tp_B = sum((y_pred == 'B')&(y_test == 'B'))\n",
    "\n",
    "    # Calculate each iteration's macro average metrics\n",
    "    # First calculate for class A\n",
    "    accuracy_A = (tp_A + tn_A) / (tp_A + tn_A + fp_A + fn_A)\n",
    "    precision_A = tp_A / (tp_A + fp_A)\n",
    "    recall_A = tp_A / (tp_A + fn_A)\n",
    "    tn_rate_A = tn_A / (tn_A + fp_A)\n",
    "    f1_A = 2 * (precision_A * recall_A) / (precision_A + recall_A)\n",
    "\n",
    "    # Calculate for class B\n",
    "    accuracy_B = (tp_B + tn_B) / (tp_B + tn_B + fp_B + fn_B)\n",
    "    precision_B = tp_B / (tp_B + fp_B)\n",
    "    recall_B = tp_B / (tp_B + fn_B) \n",
    "    tn_rate_B = tn_B / (tn_B + fp_B)\n",
    "    f1_B = 2 * (precision_B * recall_B) / (precision_B + recall_B)\n",
    "\n",
    "    # Accumulate macro-average metrics for each class\n",
    "    total_fold_accuracy_macro_A += accuracy_A\n",
    "    total_fold_precision_macro_A += precision_A\n",
    "    total_fold_recall_macro_A += recall_A\n",
    "    total_fold_tn_rate_macro_A += tn_rate_A\n",
    "    total_fold_f1_macro_A += f1_A\n",
    "    \n",
    "    total_fold_accuracy_macro_B += accuracy_B\n",
    "    total_fold_precision_macro_B += precision_B\n",
    "    total_fold_recall_macro_B += recall_B\n",
    "    total_fold_tn_rate_macro_B += tn_rate_B\n",
    "    total_fold_f1_macro_B += f1_B\n",
    "\n",
    "    # Micro-average metrics variables\n",
    "    total_tp = tp_A + tp_B\n",
    "    total_tn = tn_A + tn_B\n",
    "    total_fp = fp_A + fp_B\n",
    "    total_fn = fn_A + fn_B\n",
    "\n",
    "    # Calculate micro-average metrics\n",
    "    fold_accuracy_micro = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn)\n",
    "    fold_precision_micro = (total_tp / (total_tp + total_fp))\n",
    "    fold_recall_micro = (total_tp / (total_tp+ total_fn))\n",
    "    fold_tn_rate_micro = (total_tn / (total_tn + total_fp))\n",
    "    fold_f1_micro = 2 * (fold_precision_micro * fold_recall_micro) / (fold_precision_micro + fold_recall_micro)\n",
    "\n",
    "    total_fold_accuracy_micro += fold_accuracy_micro\n",
    "    total_fold_precision_micro += fold_precision_micro\n",
    "    total_fold_recall_micro += fold_recall_micro\n",
    "    total_fold_tn_rate_micro += fold_tn_rate_micro\n",
    "    total_fold_f1_micro += fold_f1_micro\n",
    "\n",
    "# Calculate macro average metrics\n",
    "# Calculate macro-average metrics by averaging across all folds\n",
    "accuracy_macro_A = total_fold_accuracy_macro_A / 10\n",
    "precision_macro_A = total_fold_precision_macro_A / 10\n",
    "recall_macro_A = total_fold_recall_macro_A / 10\n",
    "tn_rate_macro_A = total_fold_tn_rate_macro_A / 10\n",
    "f1_macro_A = total_fold_f1_macro_A / 10\n",
    "\n",
    "accuracy_macro_B = total_fold_accuracy_macro_B / 10\n",
    "precision_macro_B = total_fold_precision_macro_B / 10\n",
    "recall_macro_B = total_fold_recall_macro_B / 10\n",
    "tn_rate_macro_B = total_fold_tn_rate_macro_B / 10\n",
    "f1_macro_B = total_fold_f1_macro_B / 10\n",
    "\n",
    "# Combine the macro-average metrics for class A and class B\n",
    "accuracy_macro = (accuracy_macro_A + accuracy_macro_B) / 2\n",
    "precision_macro = (precision_macro_A + precision_macro_B) / 2\n",
    "recall_macro = (recall_macro_A + recall_macro_B) / 2\n",
    "tn_rate_macro = (tn_rate_macro_A + tn_rate_macro_B) / 2\n",
    "f1_macro = (f1_macro_A + f1_macro_B) / 2\n",
    "\n",
    "# Micro-average metrics\n",
    "accuracy_micro = total_fold_accuracy_micro / 10\n",
    "recall_micro = total_fold_recall_micro / 10\n",
    "tn_rate_micro = total_fold_tn_rate_micro / 10\n",
    "precision_micro = total_fold_precision_micro / 10\n",
    "f1_micro = total_fold_f1_micro / 10\n",
    "\n",
    "print(\"Macro Averages:\")\n",
    "print(\"Accuracy: \",accuracy_macro)\n",
    "print(\"TPrate (Recall): \" ,recall_macro)\n",
    "print(\"TNrate: \", tn_rate_macro)\n",
    "print(\"Precision: \",precision_macro)\n",
    "print(\"F-Score: \" ,f1_macro)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nMicro Averages:\")\n",
    "print(\"Accuracy: \",accuracy_micro)\n",
    "print(\"Tprate (Recall): \",recall_micro)\n",
    "print(\"Tnrate: \", tn_rate_micro)\n",
    "print(\"Precision: \", precision_micro)\n",
    "print(\"F-Score: \",f1_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate evaluation metrics\n",
    "    \n",
    "    # accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    # precision = tp / (tp + fp)\n",
    "    # recall = tp / (tp + fn) \n",
    "    # tn_rate = tn / (tn + fp)\n",
    "    # f1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply feature-selection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('dataset/data.csv')\n",
    "\n",
    "X = data.drop(columns=['class'])\n",
    "y = data['class']\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object' and len(X[column].unique()) == 2:\n",
    "        X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "# X_train: Feature matrix, y_train: Target vector\n",
    "# Compute mutual information\n",
    "\n",
    "mi_scores = mutual_info_classif(X, y, random_state=32)\n",
    "\n",
    "feature_scores = dict(zip(X.columns, mi_scores))\n",
    "\n",
    "sorted_features = sorted(feature_scores.items(), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "top_features = [feature[0] for feature in sorted_features[:90]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will create a data frame with selected features \n",
    "## Then will run naive bayes with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[top_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Averages:\n",
      "Accuracy:  0.9927371712140767\n",
      "TPrate (Recall):  0.9929263899611274\n",
      "TNrate:  0.9929263899611274\n",
      "Precision:  0.992606191219768\n",
      "F-Score:  0.9927305753368805\n",
      "\n",
      "\n",
      "Micro Averages:\n",
      "Accuracy:  0.9927371712140767\n",
      "Tprate (Recall):  0.9927371712140767\n",
      "Tnrate:  0.9927371712140767\n",
      "Precision:  0.9927371712140767\n",
      "F-Score:  0.9927371712140767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "\n",
    "# use n_splits = 10 for 10-folds\n",
    "# Initialize stratified 10-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Parameters for calculating macro-average metrics\n",
    "tn_A, fp_A, fn_A, tp_A = 0,0,0,0\n",
    "tn_B, fp_B, fn_B, tp_B = 0,0,0,0\n",
    "\n",
    "\n",
    "# Initialize variables for accumulating macro-average metrics for class A\n",
    "total_fold_accuracy_macro_A = 0\n",
    "total_fold_precision_macro_A = 0\n",
    "total_fold_recall_macro_A = 0\n",
    "total_fold_tn_rate_macro_A = 0\n",
    "total_fold_f1_macro_A = 0\n",
    "\n",
    "# Initialize variables for accumulating macro-average metrics for class B\n",
    "total_fold_accuracy_macro_B = 0\n",
    "total_fold_precision_macro_B = 0\n",
    "total_fold_recall_macro_B = 0\n",
    "total_fold_tn_rate_macro_B = 0\n",
    "total_fold_f1_macro_B = 0\n",
    "\n",
    "# Parameters for calculating micro-average metrics\n",
    "\n",
    "total_fold_accuracy_micro = 0\n",
    "total_fold_precision_micro = 0\n",
    "total_fold_recall_micro = 0\n",
    "total_fold_tn_rate_micro = 0 \n",
    "total_fold_f1_micro = 0\n",
    "\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in skf.split(X2, y):\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train Naive Bayes classifier\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    # tn means the model predicted the negative and the actual label was also negative\n",
    "    # fp means the model predicted the positive and the actual label was negative\n",
    "    # fn means the model predicted the negative and the actual label was positive\n",
    "    # tn means the model predicted the negative and the actual label was also negative\n",
    "\n",
    "    # our negative class is B\n",
    "    # our positive class is A\n",
    "    tn_A = sum((y_pred == 'B')&(y_test == 'B'))\n",
    "    fp_A = sum((y_pred == 'A')&(y_test == 'B'))\n",
    "    fn_A = sum((y_pred == 'B')&(y_test == 'A'))\n",
    "    tp_A = sum((y_pred == 'A')&(y_test == 'A'))\n",
    "    \n",
    "    # our negative class is A\n",
    "    # our positive class is B\n",
    "    tn_B = sum((y_pred == 'A')&(y_test == 'A'))\n",
    "    fp_B = sum((y_pred == 'B')&(y_test == 'A'))\n",
    "    fn_B = sum((y_pred == 'A')&(y_test == 'B'))\n",
    "    tp_B = sum((y_pred == 'B')&(y_test == 'B'))\n",
    "\n",
    "    # Calculate each iteration's macro average metrics\n",
    "    # First calculate for class A\n",
    "    accuracy_A = (tp_A + tn_A) / (tp_A + tn_A + fp_A + fn_A)\n",
    "    precision_A = tp_A / (tp_A + fp_A)\n",
    "    recall_A = tp_A / (tp_A + fn_A)\n",
    "    tn_rate_A = tn_A / (tn_A + fp_A)\n",
    "    f1_A = 2 * (precision_A * recall_A) / (precision_A + recall_A)\n",
    "\n",
    "    # Calculate for class B\n",
    "    accuracy_B = (tp_B + tn_B) / (tp_B + tn_B + fp_B + fn_B)\n",
    "    precision_B = tp_B / (tp_B + fp_B)\n",
    "    recall_B = tp_B / (tp_B + fn_B) \n",
    "    tn_rate_B = tn_B / (tn_B + fp_B)\n",
    "    f1_B = 2 * (precision_B * recall_B) / (precision_B + recall_B)\n",
    "\n",
    "    # Accumulate macro-average metrics for each class\n",
    "    total_fold_accuracy_macro_A += accuracy_A\n",
    "    total_fold_precision_macro_A += precision_A\n",
    "    total_fold_recall_macro_A += recall_A\n",
    "    total_fold_tn_rate_macro_A += tn_rate_A\n",
    "    total_fold_f1_macro_A += f1_A\n",
    "    \n",
    "    total_fold_accuracy_macro_B += accuracy_B\n",
    "    total_fold_precision_macro_B += precision_B\n",
    "    total_fold_recall_macro_B += recall_B\n",
    "    total_fold_tn_rate_macro_B += tn_rate_B\n",
    "    total_fold_f1_macro_B += f1_B\n",
    "\n",
    "    # Micro-average metrics variables\n",
    "    total_tp = tp_A + tp_B\n",
    "    total_tn = tn_A + tn_B\n",
    "    total_fp = fp_A + fp_B\n",
    "    total_fn = fn_A + fn_B\n",
    "\n",
    "    # Calculate micro-average metrics\n",
    "    fold_accuracy_micro = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn)\n",
    "    fold_precision_micro = (total_tp / (total_tp + total_fp))\n",
    "    fold_recall_micro = (total_tp / (total_tp+ total_fn))\n",
    "    fold_tn_rate_micro = (total_tn / (total_tn + total_fp))\n",
    "    fold_f1_micro = 2 * (fold_precision_micro * fold_recall_micro) / (fold_precision_micro + fold_recall_micro)\n",
    "\n",
    "    total_fold_accuracy_micro += fold_accuracy_micro\n",
    "    total_fold_precision_micro += fold_precision_micro\n",
    "    total_fold_recall_micro += fold_recall_micro\n",
    "    total_fold_tn_rate_micro += fold_tn_rate_micro\n",
    "    total_fold_f1_micro += fold_f1_micro\n",
    "\n",
    "# Calculate macro average metrics\n",
    "# Calculate macro-average metrics by averaging across all folds\n",
    "accuracy_macro_A = total_fold_accuracy_macro_A / 10\n",
    "precision_macro_A = total_fold_precision_macro_A / 10\n",
    "recall_macro_A = total_fold_recall_macro_A / 10\n",
    "tn_rate_macro_A = total_fold_tn_rate_macro_A / 10\n",
    "f1_macro_A = total_fold_f1_macro_A / 10\n",
    "\n",
    "accuracy_macro_B = total_fold_accuracy_macro_B / 10\n",
    "precision_macro_B = total_fold_precision_macro_B / 10\n",
    "recall_macro_B = total_fold_recall_macro_B / 10\n",
    "tn_rate_macro_B = total_fold_tn_rate_macro_B / 10\n",
    "f1_macro_B = total_fold_f1_macro_B / 10\n",
    "\n",
    "# Combine the macro-average metrics for class A and class B\n",
    "accuracy_macro = (accuracy_macro_A + accuracy_macro_B) / 2\n",
    "precision_macro = (precision_macro_A + precision_macro_B) / 2\n",
    "recall_macro = (recall_macro_A + recall_macro_B) / 2\n",
    "tn_rate_macro = (tn_rate_macro_A + tn_rate_macro_B) / 2\n",
    "f1_macro = (f1_macro_A + f1_macro_B) / 2\n",
    "\n",
    "# Micro-average metrics\n",
    "accuracy_micro = total_fold_accuracy_micro / 10\n",
    "recall_micro = total_fold_recall_micro / 10\n",
    "tn_rate_micro = total_fold_tn_rate_micro / 10\n",
    "precision_micro = total_fold_precision_micro / 10\n",
    "f1_micro = total_fold_f1_micro / 10\n",
    "\n",
    "print(\"Macro Averages:\")\n",
    "print(\"Accuracy: \",accuracy_macro)\n",
    "print(\"TPrate (Recall): \" ,recall_macro)\n",
    "print(\"TNrate: \", tn_rate_macro)\n",
    "print(\"Precision: \",precision_macro)\n",
    "print(\"F-Score: \" ,f1_macro)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nMicro Averages:\")\n",
    "print(\"Accuracy: \",accuracy_micro)\n",
    "print(\"Tprate (Recall): \",recall_micro)\n",
    "print(\"Tnrate: \", tn_rate_micro)\n",
    "print(\"Precision: \", precision_micro)\n",
    "print(\"F-Score: \",f1_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random state 32, k = 90, 0.9927\n",
    "## Selected Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['odor=n',\n",
       " 'odor=f',\n",
       " 'stalk-surface-above-ring=k',\n",
       " 'stalk-surface-below-ring=k',\n",
       " 'gill-color=b',\n",
       " 'gill-size',\n",
       " 'spore-print-color=h',\n",
       " 'ring-type=l',\n",
       " 'ring-type=p',\n",
       " 'stalk-surface-above-ring=s',\n",
       " 'bruises?',\n",
       " 'population=v',\n",
       " 'stalk-surface-below-ring=s',\n",
       " 'spore-print-color=n',\n",
       " 'spore-print-color=k',\n",
       " 'stalk-root=b',\n",
       " 'gill-spacing=w',\n",
       " 'gill-spacing=c',\n",
       " 'spore-print-color=w',\n",
       " 'habitat=p',\n",
       " 'odor=y',\n",
       " 'stalk-color-above-ring=g',\n",
       " 'odor=s',\n",
       " 'gill-color=n',\n",
       " 'stalk-color-below-ring=g',\n",
       " 'stalk-color-above-ring=b',\n",
       " 'population=n',\n",
       " 'odor=a',\n",
       " 'ring-type=e',\n",
       " 'population=a',\n",
       " 'odor=l',\n",
       " 'stalk-color-above-ring=n',\n",
       " 'stalk-color-below-ring=b',\n",
       " 'stalk-color-above-ring=p',\n",
       " 'gill-color=u',\n",
       " 'stalk-color-above-ring=w',\n",
       " 'stalk-root=e',\n",
       " 'stalk-color-below-ring=n',\n",
       " 'stalk-root=c',\n",
       " 'cap-shape=b',\n",
       " 'odor=p',\n",
       " 'stalk-surface-below-ring=y',\n",
       " 'stalk-color-below-ring=w',\n",
       " 'habitat=l',\n",
       " 'stalk-color-below-ring=p',\n",
       " 'stalk-color-above-ring=o',\n",
       " 'ring-number=t',\n",
       " 'odor=c',\n",
       " 'gill-color=w',\n",
       " 'habitat=g',\n",
       " 'stalk-color-below-ring=o',\n",
       " 'gill-color=e',\n",
       " 'gill-color=k',\n",
       " 'population=s',\n",
       " 'ring-number=n',\n",
       " 'odor=m',\n",
       " 'veil-color=n',\n",
       " 'stalk-color-above-ring=e',\n",
       " 'stalk-surface-below-ring=f',\n",
       " 'population=c',\n",
       " 'cap-shape=k',\n",
       " 'habitat=m',\n",
       " 'habitat=w',\n",
       " 'stalk-color-above-ring=c',\n",
       " 'cap-color=e',\n",
       " 'gill-attachment=a',\n",
       " 'gill-color=g',\n",
       " 'ring-number=o',\n",
       " 'cap-shape=c',\n",
       " 'spore-print-color=u',\n",
       " 'spore-print-color=r',\n",
       " 'spore-print-color=y',\n",
       " 'cap-color=y',\n",
       " 'cap-surface=y',\n",
       " 'cap-surface=s',\n",
       " 'cap-surface=g',\n",
       " 'gill-color=h',\n",
       " 'cap-surface=f',\n",
       " 'gill-color=o',\n",
       " 'habitat=u',\n",
       " 'veil-color=w',\n",
       " 'stalk-color-below-ring=y',\n",
       " 'gill-attachment=f',\n",
       " 'gill-color=y',\n",
       " 'cap-shape=s',\n",
       " 'ring-type=n',\n",
       " 'gill-color=r',\n",
       " 'stalk-surface-above-ring=f',\n",
       " 'stalk-root=r',\n",
       " 'stalk-color-above-ring=y']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Calculate chi-square scores and p-values for the entire dataset\n",
    "chi2_scores, _ = chi2(X, y)\n",
    "\n",
    "# Create a dictionary mapping feature names to their chi-square scores\n",
    "feature_scores = dict(zip(X.columns, chi2_scores))\n",
    "\n",
    "# Sort features based on their chi-square scores in descending order\n",
    "sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top k features with the highest chi-square scores\n",
    "k = 120 # Number of features to select\n",
    "top_features = [feature[0] for feature in sorted_features[:k]]\n",
    "\n",
    "X3 = X[top_features].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Averages:\n",
      "Accuracy:  0.9018968243869632\n",
      "TPrate (Recall):  0.903012466269168\n",
      "TNrate:  0.903012466269168\n",
      "Precision:  0.9229343425773788\n",
      "F-Score:  0.8971061950648327\n",
      "\n",
      "\n",
      "Micro Averages:\n",
      "Accuracy:  0.9018968243869632\n",
      "Tprate (Recall):  0.9018968243869632\n",
      "Tnrate:  0.9018968243869632\n",
      "Precision:  0.9018968243869632\n",
      "F-Score:  0.9018968243869632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "\n",
    "# use n_splits = 10 for 10-folds\n",
    "# Initialize stratified 10-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Parameters for calculating macro-average metrics\n",
    "tn_A, fp_A, fn_A, tp_A = 0,0,0,0\n",
    "tn_B, fp_B, fn_B, tp_B = 0,0,0,0\n",
    "\n",
    "\n",
    "# Initialize variables for accumulating macro-average metrics for class A\n",
    "total_fold_accuracy_macro_A = 0\n",
    "total_fold_precision_macro_A = 0\n",
    "total_fold_recall_macro_A = 0\n",
    "total_fold_tn_rate_macro_A = 0\n",
    "total_fold_f1_macro_A = 0\n",
    "\n",
    "# Initialize variables for accumulating macro-average metrics for class B\n",
    "total_fold_accuracy_macro_B = 0\n",
    "total_fold_precision_macro_B = 0\n",
    "total_fold_recall_macro_B = 0\n",
    "total_fold_tn_rate_macro_B = 0\n",
    "total_fold_f1_macro_B = 0\n",
    "\n",
    "# Parameters for calculating micro-average metrics\n",
    "\n",
    "total_fold_accuracy_micro = 0\n",
    "total_fold_precision_micro = 0\n",
    "total_fold_recall_micro = 0\n",
    "total_fold_tn_rate_micro = 0 \n",
    "total_fold_f1_micro = 0\n",
    "\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in skf.split(X3, y):\n",
    "    X_train, X_test = X3.iloc[train_index], X3.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train Naive Bayes classifier\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    # tn means the model predicted the negative and the actual label was also negative\n",
    "    # fp means the model predicted the positive and the actual label was negative\n",
    "    # fn means the model predicted the negative and the actual label was positive\n",
    "    # tn means the model predicted the negative and the actual label was also negative\n",
    "\n",
    "    # our negative class is B\n",
    "    # our positive class is A\n",
    "    tn_A = sum((y_pred == 'B')&(y_test == 'B'))\n",
    "    fp_A = sum((y_pred == 'A')&(y_test == 'B'))\n",
    "    fn_A = sum((y_pred == 'B')&(y_test == 'A'))\n",
    "    tp_A = sum((y_pred == 'A')&(y_test == 'A'))\n",
    "    \n",
    "    # our negative class is A\n",
    "    # our positive class is B\n",
    "    tn_B = sum((y_pred == 'A')&(y_test == 'A'))\n",
    "    fp_B = sum((y_pred == 'B')&(y_test == 'A'))\n",
    "    fn_B = sum((y_pred == 'A')&(y_test == 'B'))\n",
    "    tp_B = sum((y_pred == 'B')&(y_test == 'B'))\n",
    "\n",
    "    # Calculate each iteration's macro average metrics\n",
    "    # First calculate for class A\n",
    "    accuracy_A = (tp_A + tn_A) / (tp_A + tn_A + fp_A + fn_A)\n",
    "    precision_A = tp_A / (tp_A + fp_A)\n",
    "    recall_A = tp_A / (tp_A + fn_A)\n",
    "    tn_rate_A = tn_A / (tn_A + fp_A)\n",
    "    f1_A = 2 * (precision_A * recall_A) / (precision_A + recall_A)\n",
    "\n",
    "    # Calculate for class B\n",
    "    accuracy_B = (tp_B + tn_B) / (tp_B + tn_B + fp_B + fn_B)\n",
    "    precision_B = tp_B / (tp_B + fp_B)\n",
    "    recall_B = tp_B / (tp_B + fn_B) \n",
    "    tn_rate_B = tn_B / (tn_B + fp_B)\n",
    "    f1_B = 2 * (precision_B * recall_B) / (precision_B + recall_B)\n",
    "\n",
    "    # Accumulate macro-average metrics for each class\n",
    "    total_fold_accuracy_macro_A += accuracy_A\n",
    "    total_fold_precision_macro_A += precision_A\n",
    "    total_fold_recall_macro_A += recall_A\n",
    "    total_fold_tn_rate_macro_A += tn_rate_A\n",
    "    total_fold_f1_macro_A += f1_A\n",
    "    \n",
    "    total_fold_accuracy_macro_B += accuracy_B\n",
    "    total_fold_precision_macro_B += precision_B\n",
    "    total_fold_recall_macro_B += recall_B\n",
    "    total_fold_tn_rate_macro_B += tn_rate_B\n",
    "    total_fold_f1_macro_B += f1_B\n",
    "\n",
    "    # Micro-average metrics variables\n",
    "    total_tp = tp_A + tp_B\n",
    "    total_tn = tn_A + tn_B\n",
    "    total_fp = fp_A + fp_B\n",
    "    total_fn = fn_A + fn_B\n",
    "\n",
    "    # Calculate micro-average metrics\n",
    "    fold_accuracy_micro = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn)\n",
    "    fold_precision_micro = (total_tp / (total_tp + total_fp))\n",
    "    fold_recall_micro = (total_tp / (total_tp+ total_fn))\n",
    "    fold_tn_rate_micro = (total_tn / (total_tn + total_fp))\n",
    "    fold_f1_micro = 2 * (fold_precision_micro * fold_recall_micro) / (fold_precision_micro + fold_recall_micro)\n",
    "\n",
    "    total_fold_accuracy_micro += fold_accuracy_micro\n",
    "    total_fold_precision_micro += fold_precision_micro\n",
    "    total_fold_recall_micro += fold_recall_micro\n",
    "    total_fold_tn_rate_micro += fold_tn_rate_micro\n",
    "    total_fold_f1_micro += fold_f1_micro\n",
    "\n",
    "# Calculate macro average metrics\n",
    "# Calculate macro-average metrics by averaging across all folds\n",
    "accuracy_macro_A = total_fold_accuracy_macro_A / 10\n",
    "precision_macro_A = total_fold_precision_macro_A / 10\n",
    "recall_macro_A = total_fold_recall_macro_A / 10\n",
    "tn_rate_macro_A = total_fold_tn_rate_macro_A / 10\n",
    "f1_macro_A = total_fold_f1_macro_A / 10\n",
    "\n",
    "accuracy_macro_B = total_fold_accuracy_macro_B / 10\n",
    "precision_macro_B = total_fold_precision_macro_B / 10\n",
    "recall_macro_B = total_fold_recall_macro_B / 10\n",
    "tn_rate_macro_B = total_fold_tn_rate_macro_B / 10\n",
    "f1_macro_B = total_fold_f1_macro_B / 10\n",
    "\n",
    "# Combine the macro-average metrics for class A and class B\n",
    "accuracy_macro = (accuracy_macro_A + accuracy_macro_B) / 2\n",
    "precision_macro = (precision_macro_A + precision_macro_B) / 2\n",
    "recall_macro = (recall_macro_A + recall_macro_B) / 2\n",
    "tn_rate_macro = (tn_rate_macro_A + tn_rate_macro_B) / 2\n",
    "f1_macro = (f1_macro_A + f1_macro_B) / 2\n",
    "\n",
    "# Micro-average metrics\n",
    "accuracy_micro = total_fold_accuracy_micro / 10\n",
    "recall_micro = total_fold_recall_micro / 10\n",
    "tn_rate_micro = total_fold_tn_rate_micro / 10\n",
    "precision_micro = total_fold_precision_micro / 10\n",
    "f1_micro = total_fold_f1_micro / 10\n",
    "\n",
    "print(\"Macro Averages:\")\n",
    "print(\"Accuracy: \",accuracy_macro)\n",
    "print(\"TPrate (Recall): \" ,recall_macro)\n",
    "print(\"TNrate: \", tn_rate_macro)\n",
    "print(\"Precision: \",precision_macro)\n",
    "print(\"F-Score: \" ,f1_macro)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nMicro Averages:\")\n",
    "print(\"Accuracy: \",accuracy_micro)\n",
    "print(\"Tprate (Recall): \",recall_micro)\n",
    "print(\"Tnrate: \", tn_rate_micro)\n",
    "print(\"Precision: \", precision_micro)\n",
    "print(\"F-Score: \",f1_micro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
